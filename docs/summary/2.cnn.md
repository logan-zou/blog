# 卷积神经网络

## 一、基础理论

1. 基于原则：空间不变性

2. CNN 的两个原则：① 平移不变性：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应；② 局部性：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系

3. CNN 处理图像：
    
    输入 $ x \in R^{a\times b \times c}$，其中 a、b 分别为长、宽的维度，c 为颜色通道数，黑白照片 c = 1， 彩色照片 c = 3；

    隐藏层参数 $ H \in R^{a \times b \times c \times d}$，其中 a、b、c 分别为输入的长、宽、通道数，d 为特征数也就是卷积核数，一个三维张量可以看作一个卷积核，一个卷积核在一个感受野（假设卷积核长n）上的操作实则是将感受野中的所有输入 $x^n \in R^{n \times n \times c}$ 卷积为一个标量，然后卷积核会滑动覆盖整个图像，从而产生一个二维输出 $y^n \in R^{m \times m}$，$m = (a - n + 2p) / s + 1$，此处我们假设 $a = b$，p 为补0值（单侧），s 为步长。然后 d 个卷积核的输出重叠形成该层的最终输出 $ y \in R^{m \times m \times d}$。

    最后经过池化，输出的通道数不变，图片尺寸会变小，例如对上一层输出 y 做 $2\times 2$的池化，得到输出 $y_{pool} \in R^{\frac{m}{2}\times \frac{m}{2} \times d}$。

4. CNN 中的卷积实则是互运算，即对于输入 $d_{in}$：

    $$d_{in} = \begin{pmatrix} 0 & 1 \\ 3 & 4\end{pmatrix}$$

    卷积核 kernel:

    $$kernel = \begin{pmatrix}0 & 1 \\ 2 & 3\end{pmatrix}$$

    互运算计算结果 $d_{out}$：

    $$d_{out} = 0 \times 0 + 1 \times 1 + 3 \times 2 + 4 \times 3 = 19$$

5. 实现二维互相关操作：

    ```python
    def corr2d(X, Y, p=0, s=1):
        # 二维互相关运算，X 为输入向量，Y 为卷积核
        # p 为补0值，s 为步长
        # 获取卷积核的维度
        h, w = Y.shape
        # 初始化一个输出向量
        # 输出向量的维度为 m，n
        # m，n的计算方法如上
        m = (X.shape[0] - h + 2 * p) // s + 1
        n = (X.shape[1] - w + 2 * p) // s + 1
        output = np.zeros((m, n))

        # 逐个对输出向量进行填充
        for i in range(output.shape[0]):
            for j in range(output.shape[1]):
                # 互运算操作本身等同于矩阵相乘再求和
                output[i][j] = (X[i:i+h, j:j+w] * Y).sum()

        return output

    ```

5. 池化：卷积神经网络的平移不变性，是池化层赋予的。

    ① 均值池化：抑制由领域大小受限造成的估计值方差增大现象，对背景的保留效果好（相当于增大感受野）

    ② 最大值池化：抑制网络参数误差造成估计均值偏移问题，更好提取纹理信息（去除较小的噪音、冗余数据）

6. 池化的反向传播：将一个像素的 loss (梯度) 传递给4个像素，且需要保证传递的 loss 总和不变。

    ① 均值池化：将值的梯度均等分为 n*n 份分配给上一层，以保证池化 前后梯度之和保存不变；

    ② 最大池化：把梯度直接传给前一层值最大的一个像素，而其他像素不接受梯度，也就是为 0；

7. CNN 为什么具有平移不变性：

    平移不变性=卷积+最大池化。卷积层具有平移等变性，池化层具有平移不变性。卷积神经网络的平移不变性，是池化层赋予的。

    卷积层具有平移等变性，也就是说卷积层对平移是敏感的，输入的平移能等价地影响输出。直观地，如果把一张输入图像先平移后卷积，其结果与先卷积后平移效果是一样的。如果我们移动输入图像中的物体，它的表示也会在输出中移动同样的量。该特性来源于卷积核的参数共享。

    池化层具有（近似）平移不变性，也就是说池化层对平移不敏感。不管采用什么样的池化函数，当输入做出少量平移时，池化能够帮助输入的表示近似不变。例如我们使用最大池化，只要变换不影响到最大值，我们的池化结果不会收到影响。平均池化的近似不变性就稍弱些。

8. im2col：即把包含批数量的四维数据转换成二维数据，再使用 numpy 的矩阵运算得到结果；再具体实现上，会将每个滑动窗口里的输入值转为列向量拼接成转换后的输入，再将卷积核转化为行向量，进行矩阵运算再展开。

9. CNN 的局限性：
    
    ① 以 CNN 为代表的前馈神经网络使用了条件独立假设，其特征提取范围受到限制；而循环神经网络或者 Attention 机制的模型能够看到序列整体的信息，因此对于序列建模任务，单纯的CNN存在先天不足。

    ② 使用CNN做序列任务的优点在于其共享权重的机制，使得训练速度相对较快；但是其最大的缺点在于CNN无法构建长距离依存关系。

## 二、手写实现

本部分基于 numpy 手写一个 CNN 网络，以增进对 CNN 的理解。

### 1. 卷积层

卷积层的核心在于实现互运算的计算过程，此处我们定义一个 3*3 滤波器来进行卷积，分别定义了两个函数，一个从原输入中对应截取感受野范围内的输入，另一个进行前向计算：

```python
# 实现一个 3 * 3 的滤波器
import numpy as np

class Conv3x3():
    # 3 * 3滤波器
    # 构造函数
    def __init__(self, num_filter : int):
        # num_filter：滤波器数量
        self.num_filter = num_filter
        # 初始化 filter 权重
        self.filters = np.random.randn(num_filter, 3, 3) / 9

    def iterate_region(self, image):
        # 每轮生成图像的对应区间
        h, w = image.shape
        # 每一次迭代
        for i in range(h - 2):
            for j in range(w - 2):
                # 每一次产生 3*3 的区间
                im_region = image[i:(i+3), j:(j+3)]
                # 将产生的区间和迭代起点添加到迭代器
                yield im_region, i, j

    def forward(self, input):
        # 前向传播    
        # 和基本的卷积实现类似，只是加入了迭代器
        h, w = input.shape
        # 初始化 output 矩阵
        output = np.zeros((h -  2, w - 2, self.num_filter))

        # 使用上面定义的迭代器
        for im_region, i, j in self.iterate_region(input):
            # 这里的filters是三维的，实则是y的两个维度分别和x做元素乘积，即对应位置相乘，再分别对两个维度做求和
            output[i][j] = np.sum(im_region * self.filters, axis=(1,2))

        return output
```

### 2. 池化层

池化层的计算较简单，整体逻辑同卷积层相似，只是运算不一致，此处我们实现一个2*2的最大池化：

```python
# 实现一个2*2的最大池化层
class Max_pooling():

    # 同上，分批迭代感受野范围内的输入
    def iter_region(self, image):
        # 首先获取输入的长和宽，卷积的输出应该是三维的，第三维等于num_filters
        h_, w_, _ = image.shape
        # 池化是有步长的，2*2池化步长为2
        h = h_ // 2
        w = w_ // 2
        # 进行迭代
        for i in range(h):
            for j in range(w):
                # 因为是 2*2 的池化，所以最终结果-1
                yield image[i*2:i*2+2, j*2:j*2+2], i, j

    # 前向计算函数
    def forward(self, input):
        # 获取输入的维度
        h, w, chennels = input.shape
        # 初始化一个输出矩阵
        output = np.zeros((h // 2, w // 2, chennels))
        # 迭代计算输出
        for im_region, i, j in self.iter_region(input):
            output[i][j] = np.max(im_region, axis=(0,1))
        return output

```

### 3. SoftMax 层

在进行卷积、池化之后，需要经过一层 Softmax 输出分类，SoftMax 层会现先将前面得到的输出矩阵展平，然后进行运算：

```python
# 定义一个 SoftMax 层
class Softmax():

    def __init__(self, input_dims, output_dims):
        # 分别是输入、输出的维度（均是展平的）
        # 初始化权重，此处除以输入维度是为了避免初始化权重太大
        self.weight = np.random.randn(input_dims, output_dims) / input_dims
        # 初始化偏置，输出每个维度一个偏置
        self.bias = np.random.randn(output_dims)

    # 前向计算函数
    def forward(self, input):
        # 先获取输入的展平
        inputs = input.flatten()
        # 展平输入乘以权重加上偏置得到输出
        output = np.dot(inputs, self.weight) + self.bias
        # SoftMax 计算
        exp = np.exp(output)
        return exp / np.sum(exp, axis=0)
```

### 4. 整体网络

基于前面的若干层，搭建整体 CNN 网络：

```python
class CNN():

    def __init__(self, input_dims, num_filter, output_dims):
        self.conv = Conv3x3(num_filter)
        self.pooling = Max_pooling()
        self.softmax = Softmax(((input_dims - 2) // 2)**2*num_filter, output_dims)

    def forward(self, input, label):
        # 将输入从[0,255]变换到[-0.5,0.5]便于计算 
        input_ = input / 255 - 0.5
        out = self.conv.forward(input_)
        out = self.pooling.forward(out)
        out = self.softmax.forward(out)

        # 使用交叉熵计算损失
        loss = -np.log(out[label])

        # 计算准确率
        acc = 1 if np.argmax(out) == label else 0

        return out, loss, acc
```

### 5. 对比——使用Pytorch搭建一个 CNN

我们可以用 Pytorch 快速高效搭建一个和上述 CNN 结构一致的网络，从而对比理解 Pytorch 中的 CNN 模块：

```python
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    # 使用 Pytorch 实现一个 CNN

    def __init__(self):
        # 继承基类的构造函数
        super(Net, self).__init__()
        # 卷积层
        # 此处的 in_channels 为输入图像通道数，此处为1；out_channels 即为我们给定的卷积核数也即是输出通道数
        self.conv = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)
        # 池化层
        self.pooling = nn.MaxPool2d(2)
        # 我们使用一个线性层替代 Softmax，在前向函数中实现 Softmax
        # 输入维度为 通道数 * 长 * 宽，其中长、宽需要经过输入图像形状经过每层卷积和池化计算得到
        # 此处，通道数为3，长和宽均为（图像尺寸 28 - 卷积核3 + 1 ）/ 池化尺寸2 = 13
        self.linear = nn.Linear(3*13*13, 10)

    def forward(self, inputs):
        # 前向计算函数
        # print(inputs.dtype)
        out = self.conv(inputs)
        out = self.pooling(out)
        # 需要将卷积后的矩阵展开到一维
        out = out.view(-1, 3*13*13)
        # print(out.shape)
        out = self.linear(out)
        # 再做一个 Softmax
        # print(out.shape)
        # print(out)
        return F.softmax(out, dim=1)
```